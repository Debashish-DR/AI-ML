{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be489633-0d6c-4439-8e2e-07873ec5f303",
   "metadata": {},
   "source": [
    "NLP : Natural Language Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cea51010-2abb-4839-adf5-a40bc6bc626a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NLP is of two types --> (1). NLU(Natural language understanding)  (2). NLG(Natural language Generation)\n",
    "#Basic Technologies in NLP \n",
    "#->Corpus\n",
    "#->Document\n",
    "#->Words\n",
    "#->Vocabulary(finds unique words)\n",
    "#->Vectors(it converts the text data to number that can be understand by machine)\n",
    "#->Stopwords(commonly used words in a sentence)\n",
    "#->Tokens(it can be a sentence or can be a word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c938ee4-8e20-4eee-b0db-723012d62e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk : Natural Language Tool kit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddd39650-6a57-4ac4-8757-c9fec06bdf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\python310\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\python310\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\python310\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\python310\\lib\\site-packages (from nltk) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in c:\\python310\\lib\\site-packages (from nltk) (4.66.2)\n",
      "Requirement already satisfied: colorama in c:\\python310\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d551604-9703-4979-a788-53679f6148cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\python310\\lib\\site-packages (24.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d43aa0fa-9cf2-442e-b3c0-1ee74e34addc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f5506d4-e0f1-4383-8f9e-5818ad296a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am Debasish Rout. I love travelling. Photography, Videography defines my hoby. In professional career I am pursuing B Tech from SOA University'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = \"I am Debasish Rout. I love travelling. Photography, Videography defines my hoby. In professional career I am pursuing B Tech from SOA University\"\n",
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba6de40d-cc0d-4988-adf0-b11baa592c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am Debasish Rout.',\n",
       " 'I love travelling.',\n",
       " 'Photography, Videography defines my hoby.',\n",
       " 'In professional career I am pursuing B Tech from SOA University']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import sent_tokenize\n",
    "sent_tokenize(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f20d23a7-c04c-41e1-a466-65e1dcc23b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\91732\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28b50f87-74e3-4f59-aa40-ea8bdd326c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming : it finds the nearest rootword by spelling\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b9889e3-2250-463c-954c-800f8fa4142e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'car'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.stem('CARS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19790ac7-1461-4c2c-a98c-bb0363277b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'went'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.stem('went')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fcc5a95-d3bc-4f0d-b434-bd7fa0b584ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'studi'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.stem('studying')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "369cb6c9-cb5f-4d3f-8a38-9f7a0a9ec13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lm = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f71dd318-5cc2-4f05-87aa-ad5d2e0db539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.lemmatize('went','v') #--> 'v' for verb ,,, 'n' for nouns ,,, 'a' for adjective ,,, 'r' for satellite adjective eg. beautiful red rose --here beautiful is satelite adj and red is adj "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "742605fe-11f0-456f-8858-2154edce5614",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\91732\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a15dfe1-403b-4c56-9e57-cf3b1e22ce98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'study'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.lemmatize('studying','v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62897498-540b-43ef-95bb-3daf27496d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Archana'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.lemmatize('Archana','n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f31f066c-fed8-470e-b21d-d77eb8439aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stopwords : \n",
    "from nltk.corpus import stopwords\n",
    "stopwords.words('English')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4badccc2-4a34-48dc-91a0-58904d7f8c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mount Everest is the highest peak in the world.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#POS tags : Parts of speech tags\n",
    "\n",
    "txt = 'Mount Everest is the highest peak in the world.'\n",
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a71ba84b-9146-4b8b-bf3c-b43ee6802ff1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_tokenize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m txt_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mword_tokenize\u001b[49m(txt)\n\u001b[0;32m      2\u001b[0m txt_tokens\n",
      "\u001b[1;31mNameError\u001b[0m: name 'word_tokenize' is not defined"
     ]
    }
   ],
   "source": [
    "txt_tokens = word_tokenize(txt)\n",
    "txt_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e725ce68-0206-468f-8905-d749feb3eeaa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'txt_tokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m txt_tags \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mpos_tag(\u001b[43mtxt_tokens\u001b[49m)\n\u001b[0;32m      2\u001b[0m txt_tags\n",
      "\u001b[1;31mNameError\u001b[0m: name 'txt_tokens' is not defined"
     ]
    }
   ],
   "source": [
    "txt_tags = nltk.pos_tag(txt_tokens)\n",
    "txt_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ac2a117-59ca-4ab6-9096-0724080d4fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Narendra Modi Chutiya Minister'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ne_chunk\n",
    "t = 'Narendra Modi Chutiya Minister'\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a67caa05-4ab5-47c3-86b2-b241dd1d2a91",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_tokenize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m t_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mword_tokenize\u001b[49m(t)\n\u001b[0;32m      2\u001b[0m t_tokens\n",
      "\u001b[1;31mNameError\u001b[0m: name 'word_tokenize' is not defined"
     ]
    }
   ],
   "source": [
    "t_tokens = word_tokenize(t)\n",
    "t_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd76a92e-7824-4a69-ba93-e9b427b19b35",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't_tokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m t_tags \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mpos_tag(\u001b[43mt_tokens\u001b[49m)\n\u001b[0;32m      2\u001b[0m t_tags\n",
      "\u001b[1;31mNameError\u001b[0m: name 't_tokens' is not defined"
     ]
    }
   ],
   "source": [
    "t_tags = nltk.pos_tag(t_tokens)\n",
    "t_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eacd354b-2ea4-4e6d-865e-2ae580e7f088",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1453152577.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[27], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    t_tags =\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from nltk import ne_chunk\n",
    "t_tags = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f27e15-e02f-4c7d-a280-ad2d8445bd0d",
   "metadata": {},
   "source": [
    "Punctuaion mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d30e369b-f685-4ccd-bc16-975631a6e8ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wow !!!, this place is so beautifull...'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = 'Wow !!!, this place is so beautifull...'\n",
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "08804141-1e8d-4b52-ad24-2620672d6678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "! ! ! , . . . "
     ]
    }
   ],
   "source": [
    "import string \n",
    "\n",
    "for c in txt:\n",
    "    if c in string.punctuation:\n",
    "        print(c,end = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06ccdb8f-fa07-4632-80e7-7ca06340a419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!', '!', '!', ',', '.', '.', '.']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punct = [c for c in txt if c in string.punctuation]\n",
    "punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e957f18f-c679-4838-a8ff-9e3f12128f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['W',\n",
       " 'o',\n",
       " 'w',\n",
       " ' ',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'i',\n",
       " 's',\n",
       " ' ',\n",
       " 'p',\n",
       " 'l',\n",
       " 'a',\n",
       " 'c',\n",
       " 'e',\n",
       " ' ',\n",
       " 'i',\n",
       " 's',\n",
       " ' ',\n",
       " 's',\n",
       " 'o',\n",
       " ' ',\n",
       " 'b',\n",
       " 'e',\n",
       " 'a',\n",
       " 'u',\n",
       " 't',\n",
       " 'i',\n",
       " 'f',\n",
       " 'u',\n",
       " 'l',\n",
       " 'l']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_punct = [c for c in txt if c not in string.punctuation]\n",
    "no_punct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca02281-c256-431b-a8fa-e688ce12b69c",
   "metadata": {},
   "source": [
    "TEXT TO SPEECH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd10126f-febb-4e01-ae0c-2f8086d42120",
   "metadata": {},
   "source": [
    "gTTS : Google Text To Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5259b74e-bc6c-4bc7-80c1-8ef9b23f2cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gtts\n",
      "  Downloading gTTS-2.5.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\python310\\lib\\site-packages (from gtts) (2.31.0)\n",
      "Requirement already satisfied: click<8.2,>=7.1 in c:\\python310\\lib\\site-packages (from gtts) (8.1.7)\n",
      "Requirement already satisfied: colorama in c:\\python310\\lib\\site-packages (from click<8.2,>=7.1->gtts) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python310\\lib\\site-packages (from requests<3,>=2.27->gtts) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python310\\lib\\site-packages (from requests<3,>=2.27->gtts) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python310\\lib\\site-packages (from requests<3,>=2.27->gtts) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python310\\lib\\site-packages (from requests<3,>=2.27->gtts) (2024.2.2)\n",
      "Downloading gTTS-2.5.1-py3-none-any.whl (29 kB)\n",
      "Installing collected packages: gtts\n",
      "Successfully installed gtts-2.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install gtts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dcf40d0b-0384-4685-a8b4-82f6ce923b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "tts = gTTS(\"Hello how are you\")\n",
    "tts.save('hey.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8480413-00fc-49cf-b31c-7de41a6ff46c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e56950-1af0-4e9d-bbfc-f772d8f2dac5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27980d6-d4da-4230-bd9a-f3c8952e64eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce95b12-0096-474e-b303-af53d74a3ccf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2861660e-2ae0-4dfb-a8a5-44a48d4a72ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
